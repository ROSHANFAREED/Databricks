ğŸ›’ Retail Sales Analytics â€” End-to-End Data Engineering Project

This project demonstrates a complete Medallion Architecture (Bronze â†’ Silver â†’ Gold) pipeline built on Databricks (Free Edition) using PySpark.

The dataset consists of one CSV file (orders) and one JSON file (customer details). Using these raw files, the pipeline:

Ingests data into Bronze layer

Cleans & transforms using PySpark (Silver layer)

Creates aggregated analytical tables (Gold layer)

Builds a full dashboard (Sales by Category, Order Trends, Customer Loyalty, etc.)

ğŸ§± Architecture Overview
Raw Data (CSV + JSON)
       â†“
Bronze Layer
       â†“
Silver Layer (cleaned, validated, typed)
       â†“
Gold Layer (aggregated KPIs)
       â†“
Dashboard (Databricks)

ğŸ“‚ Project Structure
/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ bronze_ingestion.py
â”‚   â”œâ”€â”€ silver_cleaning_transformation.py
â”‚   â””â”€â”€ gold_aggregation.py
â”‚
â”œâ”€â”€ data_sample/
â”‚   â”œâ”€â”€ orders.csv
â”‚   â””â”€â”€ customers.json
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ retail_dashboard_overview.png
â”‚   â”œâ”€â”€ sales_by_category.png
â”‚   â”œâ”€â”€ order_trends.png
â”‚   â””â”€â”€ loyalty_distribution.png
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

ğŸ¥‰ Bronze Layer â€” Raw Ingestion

The raw data contains:

orders.csv

order_id

order_date (multiple date formats)

customer_id

product_id

product_name

category

quantity

price

payment_type

order_status

customers.json

customer_id

customer_name

city

loyalty_level

Data is loaded into Bronze as-is for traceability.

ğŸ¥ˆ Silver Layer â€” Cleaning & Transformation (PySpark)

Major cleaning steps performed:

âœ” Handle multiple date formats using coalesce()
order_date = coalesce(
    to_timestamp(trim(col("order_date")), "dd/MM/yyyy"),
    to_timestamp(trim(col("order_date")), "MM/dd/yyyy"),
    to_timestamp(trim(col("order_date")), "yyyy-MM-dd"),
    to_timestamp(trim(col("order_date")), "dd-MM-yyyy"),
    to_timestamp(trim(col("order_date")), "yyyy/MM/dd"),
)

âœ” Remove spaces, convert strings to lowercase
âœ” Cast columns to correct types
âœ” Handle null or blank quantity
âœ” Remove invalid characters from price
âœ” Join CSV + JSON to create enriched dataset
ğŸ¥‡ Gold Layer â€” Business Aggregations

Final tables created:

ğŸ“Œ Total Sales per Category
ğŸ“Œ Order Trends Over Time
ğŸ“Œ Customer Loyalty Distribution
ğŸ“Œ Returned Amount by City
ğŸ“Œ Average Order Value (AOV)

Formula:

AOV = Total Sales / Number of Orders

ğŸ“Œ Average Price per Item

Formula:

Avg Price per Item = Total Revenue / Total Quantity Sold


These aggregates feed directly into the dashboard.

ğŸ“Š Dashboard (Databricks)

Below are some sample dashboard components:

Total Sales by Category

Order Trends Over Time

Returned Amount by City

Customer Loyalty Pie Chart

KPI Cards

Average Order Value

Average Price per Item

(Screenshots included inside the /dashboard folder.)

ğŸš€ How to Run This Project
1. Import the notebooks into Databricks

Menu â†’ Workspace â†’ Import

2. Upload sample CSV & JSON

Go to Data â†’ Add Data

3. Run the workflow in order

Bronze

Silver

Gold

Dashboard queries

4. Visualize results using Databricks Dashboards
ğŸ“¦ Technologies Used

Databricks (Free Edition)

PySpark / Spark SQL

Delta Tables

CSV + JSON sources

Databricks Dashboarding

ğŸ™Œ Author

Roshan Fareed
Email: roshanfareed53@gmail.com

ğŸ“ License

MIT License
